## 1. Abstract
Credit card fraud poses significant risks to financial institutions, businesses, and customers (Encora 2024) necessitating the need for effective detection methods. Whilst most institutions are embracing and developing Artificial Intelligence (AI) tools under Machine Learning (ML) and Deep Learning (DL) there are a plethora of studies being conducted to review their performance of fraud detection. This report evaluates the application of the ML Random Forest (RF) algorithm in classifying fraudulent credit card transactions.
Comparative analysis with other studies reveals that the inclusion of techniques such as the Synthetic Minority Oversampling Technique (SMOTE) significantly enhances performance in handling class imbalance. This report, which used class weight adjustment, achieved commendable but low results, therefore indicating that class weight adjustment may not suffice for highly skewed datasets. The findings underscore the importance of advanced techniques to improve fraud detection accuracy. 

## 2. Introduction
Fraud is defined as obtaining personal or financial gain through deception (Alenzi and Aljehane 2020). To mitigate losses caused by fraud, two crucial methods are employed: fraud prevention and fraud detection. Fraud prevention involves proactive measures to avert the occurrence of fraudulent activities, while fraud detection focuses on identifying fraudulent transactions carried out by fraudsters (Alenzi and Aljehane 2020).

The widespread adoption of digitalisation in all aspects of finance has led economists and social commentators to coin the term 'cashless society,' reflecting the increased use of digital and electronic forms of payment, from cryptocurrency to credit, debit, and prepaid cards (Joshi and Khaitan 2024). In Europe, cash transactions are decreasing while digital payments are rising year-over-year (appendix 1) (Bindseil and Schneeberger 2023). Globally, two-thirds of adults now make or receive digital payments, with the share in developing economies growing from 35% in 2014 to 57% in 2021 (Ansar et al. 2022).

The rise in digital payments also creates opportunities for potential illicit activities such as theft and fraud. The 2022 Neilson report stated that payment card fraud losses worldwide exceeded $32 billion in 2021 (Fulmer 2022). Credit card fraud is commonly defined as the unauthorised use of another person's credit card or credit card information, typically to make purchases or withdraw funds (Cornell Law School, no date). Given the high costs associated with credit card fraud, collaborative efforts have been made across public and private sectors and organisations to adopt and develop the use of sophisticated AI models to detect fraud.

This report presents the results of using the RF algorithm to classify fraudulent credit card transactions. While fraud detection benefits from both ML and DL algorithms, it is often advised to begin with ML and then progress to DL for more complex analysis and detection.

## 3. Literature Review
Supervised learning, a branch of ML, functions by identifying patterns and relationships between dataset features and their corresponding targets (Ali 2022). Numerous studies and reports have examined the application of ML algorithms in credit card fraud detection, consistently highlighting that supervised learning models are the most effective in identifying fraudulent activities.

Afriyie et al. (2023) reviewed the performance of three ML models— RF, Decision Tree (DT) and Logistic Regression (LR)—against simulated credit card transactions. Their findings indicated that while all models performed relatively well, the RF model stood out with a value of 98.9% for the Area Under the ROC (AUC) and an accuracy of 96%. Similarly, Khair and Sait (2018) support the use of RF in credit card fraud detection, as their model achieved a precision accuracy of 98.6% compared to DT, LR, and Support Vector Machine (SVM).

However, LR is favoured by some due to its performance against other classifiers. Alenzi and Aljehane (2020) argued that LR is the best at detecting credit card fraud when compared to K-nearest Neighbour (KNN) and Voting Classifier (VC). This superiority is attributed to the efficient preprocessing techniques used to remove outliers and handle missing values (Alenzi and Aljehane, 2020). Conversely, Awoyemi et al. (2017) conducted a comparative analysis of different ML methods on a European credit card fraud dataset, and found that Naïve Bayes (NB), LR, and KNN achieved accuracies of 97.92%, 54.86%, and 97.69%, respectively.

Preprocessing credit card fraud data is essential due to its positive impact on the classifier performance, noise reduction, and the accurate identification of fraudulent transactions (Ileberi 2022; Gedela and Karthikeyan 2022). The AdaBoost algorithm enhances this process by iteratively training weak classifiers and assigning higher weights to previously misclassified samples, thereby focusing on challenging cases and improving overall performance (Data Science Wizards 2023).

Researchers frequently use the AdaBoost algorithm for fraud detection, as it boosts model accuracy and performance (Nithin et al. 2020). Chaudhari et al. (2024) reported significant improvements in the accuracy and efficiency of fraud detection with ensemble learning approaches like AdaBoost. Gedela and Karthikeyan (2022) also found that AdaBoost outperformed other ML algorithms, achieving an accuracy of 99.43%.

## 4.Methodology
In this section, we will explore the methodology used to analyse the credit card fraud detection within the dataset. The analysis in this report relies on Python and its related ML libraries for comprehensive data processing and modelling.
### 4.1. Analytics
For financial institutions and businesses, the main concerns with fraud include financial losses, the burden of investigating and rectifying fraudulent transactions, increased security and cybersecurity costs, and potential loss of reputation, which can diminish customer trust and loyalty (Jacobs 2024). For customers, the psychological impact can be profound, leading to feelings of violation, anxiety, and mistrust towards digital transactions (Feedzai 2024). The erosion of trust in financial systems and businesses can have long-term detrimental effects on customer behaviour and market stability (Jacobs 2024).

The primary goal of this analysis is to accurately detect fraudulent credit card transactions. The dataset, sourced from Kaggle, contained over 4,000 notebooks from other programmers as of June 2024. The dataset included transactions over two days in September 2013 by European credit card holders. Due to confidentiality issues, the original features and background data were not available. This analysis aims to assess the effectiveness of a ML algorithm at detecting fraudulent credit card transactions in the dataset.
### 4.2. Data Characteristics
The dataset's quality was poor due to the presence of only numerical input variables resulting from a Principal Component Analysis (PCA) transformation. The lack of original features and background information could potentially lead to misinterpretation and overfitting of data. Class imbalance is also evident in the dataset, with only 492 fraud cases out of 284,807 transactions over two days. Rather than removing this bias, it was decided to address the class imbalance within the algorithm to maintain result validity. Appendix 2 visually represents this class imbalance, with fraudulent transactions accounting for 0.172% of the total transactions.

Appendix 3 histograms of 'Amount' and 'Time' features illustrate distinct distributions between valid and fraudulent transactions, suggesting potential patterns exploitable by the classifier. For 'Amount', separate histograms were plotted for each class, accompanied by Kernel Density Estimate (KDE) plots to highlight distribution shapes. Valid transactions ranged from 0 to 25,000 euros, while fraudulent transactions were significantly smaller and typically fell between 0 and 2,000 euros.

Similarly, appendix 4 'Time' histograms were plotted separately for valid and fraudulent transactions, with overlaid KDE plots. These visualisations provide insights into temporal transaction patterns across both classes. Valid transactions exhibited clustered timings e.g., every 2-5 seconds or 7 seconds to 1 minute, whereas fraudulent transactions showed less structured timing patterns, likely due to the limited fraudulent data available in the dataset.

Furthermore, appendix 5 correlation matrix heatmap was generated to explore relationships among features, particularly examining the possibility of the correlation between 'Amount' and 'Time' with other PCA-transformed features. The heatmap visualises the entire dataset's feature correlations, aiding in the identification of potential linear relationships for feature selection or engineering. The heatmap revealed that 'Amount' exhibited positive correlations with features 'V7' and 'V20'. However, due to PCA transformation, the specific nature of these features ('V7' and 'V20') remains unclear.
### 4.3. Model Selection
The rise in credit card usage for financial transactions has been accompanied by an increasing incidence of fraud, as highlighted by several surveys (Alenzi and Aljehane 2020). ML algorithms have become indispensable in industries handling digital payments for fraud detection (Waylay, 2023). Supervised models like RF, DT, LR, AdaBoost, XG Boost, SVM, and Light GBM have proven effective for this purpose (Afriyie et al. 2023).

RF, a popular supervised ML algorithm, constructs an ensemble of DT to achieve more accurate predictions (Donges and Whitfield 2024). It is versatile, handling both classification and regression tasks. In classification, multiple decision trees are built using random subsets of data and features, each contributing to the final prediction by majority voting (appendix 6). For regression, predictions are averaged (Shafi 2023).

RF was chosen for its efficacy as a binary classifier, making it well-suited for credit card fraud detection, where transactions are classified as fraudulent (1) or valid (0) (Aburbeian and Ashqar 2023). Its benefits include efficient operation on large datasets, robust handling of missing data, and the ability to estimate generalisation errors internally during forest building (Chakure and Whitfield 2023).

Given the dataset's class imbalance, a class weight parameter ({0:1, 1:5}) was incorporated into the RF algorithm to address this issue. This parameter assigns greater weight to the minority fraud class, enhancing the classifier's sensitivity to fraudulent transactions. Additionally, a random state parameter (set to 42) was introduced to ensure reproducibility of results, making the algorithm's random processes produce consistent outputs across runs.
### 4.4. Model Training
The dataset underwent an 80/20 training and testing split to assess the model's performance on unseen data. This partitioning aligns with common practice in ML, influenced by the Pareto principle, also known as the 80–20 rule, which suggests that 80% of effects stem from 20% of causes (Ahmed 2022).

Prior to training, features were standardised using StandardScaler from the Sklearn library to enhance algorithm performance, ensuring they had a mean of 0 and a standard deviation of 1. Subsequently, the RF model was trained on the standardised training data. Predictions and class probabilities were generated for the test set using the trained model. The model's performance was evaluated using metrics including accuracy, precision, recall, F1 score, and Area Under the Precision-Recall Curve (AUPRC).

## 5.Results
RF demonstrated exceptional performance in detecting credit card fraud, achieving an accuracy of 99.96% (appendix 7), indicating its strong capability to distinguish between fraudulent and normal transactions. However, relying solely on accuracy can be misleading, especially in the presence of class imbalance in datasets (Wilame 2018). In such cases, other metrics should be prioritised over accuracy to provide a comprehensive assessment of model performance.

Precision (appendix 8) measures the proportion of true positive predictions among all positive predictions. Precision was recorded at 97.4%. The high precision indicates that the model effectively minimises false positives, accurately identifying most flagged transactions as fraudulent. On the other hand, Recall (appendix 9), measures the proportion of actual positives correctly identified by the model, stood at 76.5%. The moderate Recall suggests that the model effectively identifies a significant portion of fraudulent transactions but misses approximately 23.5% of actual fraud cases, which is critical in credit card fraud detection.

The F1 score (appendix 10), balancing Precision and Recall, is widely used for imbalanced datasets (Brownlee 2021). The F1 score is a particularly important metric as the minority fraudulent cases detected are of interest (Smolic 2024). With an F1 score of 85.7%, the model demonstrates a good overall performance, though there is potential for improvement, particularly in recall. 

Mean Squared Error (MSE) measures the amount of error in a model, whereas Root Mean Squared Error (RMSE) measures the average difference between a statistical model’s predicted values and the actual values (Frost no date) (Appendices 11 and 12). Both MSE and RMSE were very low, with MSE at 0.0004 and RMSE at 0.021. These metrics indicate minimal error between predicted and actual values, affirming the model's high accuracy in predicting probabilities.

The precision-recall curve is utilised to assess the performance of binary classification algorithms, particularly in scenarios where class imbalance is significant (Steen 2020). An AUPRC of 0.876 indicates a high level of performance (appendix 13), confirming that the model maintains a good balance between precision and recall over various thresholds. It is argued that in a perfect classifier the AUPRC = 1 (Steen 2020), therefore the result of 0.876 can be deemed as a good classifier. In conclusion, while RF excels in accuracy and precision for credit card fraud detection, attention to recall and other metrics is essential for a more comprehensive evaluation, especially in scenarios with class imbalance.
### 5.1. Result Comparison
Tran and Dang (2021), Khalid et al (2024, Varmedja et al (2019) and Dornadula and Geetha (2019) utilised the same credit card detection dataset as in this report. However, they employed the SMOTE to deal with the class imbalance. SMOTE mitigates the overfitting problem associated with random oversampling by focusing on the feature space and creating new instances through interpolation between neighbouring positive instances (Satpathy 2024). SMOTE was not utilised in the CSC40094 report due to computational capacity constraints that caused the program to crash during execution, hence the use of class weights to manage the class imbalance.

The RF accuracy results across various studies consistently exceeded 99%. Tran and Dang (2021) reported an accuracy of 99.95%, while Khalid et al. (2024) achieved a perfect accuracy of 100.00%. Dornadula and Geetha (2019) also achieved an accuracy of 99.98%. Varmedja et al. (2019) was the only study that reported a slightly lower accuracy of 99.93%, which remains comparable within the range.  In contrast, Nithin et al. (2020) reported an accuracy of 95.12% with their AdaBoost algorithm, highlighting RF superior performance in comparison.

While accuracy alone does not provide a comprehensive assessment, precision and recall metrics offer deeper insights into model performance. Tran and Dang (2021), Dornadula and Geetha (2019), and Khalid et al. (2024) achieved perfect precision scores of 0.999 and 1.00, respectively, thus signifying that their RF model was able to identify the true positive fraudulent cases. However, Varmedja et al. (2019) had a precision score of 0.792, which was significantly lower when compared to all models. Perfect recall scores were also attained by Tran and Dang (2021) and Khalid et al. (2024) with scores of 1.00, indicating these models effectively captured all fraudulent cases, and Varmedja et al. (2019) achieved a recall score of 0.816. Comparing these results with the CSC40094 report, it becomes apparent that the report's RF model falls short in accurately identifying fraudulent cases (Kreiger 2020).

Tran and Dang (2021) and Khalid et al. (2024) achieved nearly perfect F1 scores of 0.999 and 1.00, respectively. These impressive results suggest that their models effectively handled class imbalance, primarily due to the implementation of SMOTE. In contrast, the CSC40094 report, which employed class weight assignment to address class imbalance, achieved an F1 score of 0.857. This comparison highlights a significant difference in the ability to manage class imbalance between the methodologies. The CSC40094 report's lower F1 score indicates that class weight assignment may not sufficiently address the imbalance when dealing with biased datasets. 

Tran and Dang (2021) attained a flawless AUPRC of 1.00, showcasing exceptional performance. In contrast, the CSC40094 report achieved a commendable score of 0.876, indicating strong performance but also suggesting potential for enhancement compared to Tran and Dang's benchmark.

## 6.Conclusion
The CSC40094 report RF performance was good across all metrics. However, it fell slightly short of the nearly perfect scores reported by Tran and Dang (2021) and Khalid et al. (2024) in most areas. The CSC40094 RF precision is close to perfect, but its recall is relatively lower, therefore affecting the overall F1 score. Despite these differences, the CSC40094 results are competitive and reflect strong model performance in the context of RF classifiers.

When comparing results with other studies, it is evident that the inclusion of techniques like SMOTE, used by Tran and Dang (2021) and Khalid et al. (2024), significantly improves the performance of fraud detection models. These studies reported nearly perfect precision, recall, and F1 scores, highlighting the effectiveness of SMOTE in handling class imbalance. The CSC40094 report, which utilised class weight adjustment instead, achieved commendable but comparatively lower scores, suggesting that class weight adjustment may not be as effective in managing highly imbalanced datasets.

Overall, while the RF model shows robust performance in detecting credit card fraud, the incorporation of advanced techniques like SMOTE could further enhance its effectiveness. Future research should explore the integration of such techniques to improve recall and overall performance, ensuring more comprehensive detection of fraudulent activities in digital transactions. 
Ethical concerns surrounding AI and ML have been a topic of intense debate among governments, institutions, and regulatory bodies. The prevailing consensus is that it is crucial to address both immediate and long-term issues in policy development and ethical considerations. It is important to take into consideration the potential ethical issues that could arise in applying ML algorithms such as RF in credit card fraud detection. 

Privacy violations and fines may arise from country or regional regulations requiring customer consent (Leleko and Holoborodko 2024). For example, Europe's GDPR mandates obtaining user permission before using their personal data (Wolford no date), raising the issue of when to get informed consent, considering the possibility of people opting out. Although bias was raised in the report in regard to data imbalance and the potential impact to the results and performance. Bias, unfairness and discrimination can also unconsciously arise during creation by the programmers, interpretation of results and even through the profiling of certain areas and customer backgrounds (Rodrigues 2020) with some critics arguing that AI systems mirror human behaviour (Premuzic et al. 2019). 

In order to tackle the possible ethical issues, the dataset must be diverse, demographically unbiased, the algorithms also debiased and not fall into the Blackbox category of being difficult to explain how the results were created, then this could mitigate potential issues (Premuzic et al. 2019). Future research should continue to refine these techniques while addressing ethical implications to enhance both the performance and integrity of fraud detection systems.
